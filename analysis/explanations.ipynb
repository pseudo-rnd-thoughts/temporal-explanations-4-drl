{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Explanations of RL agent with Baseline Temporal Explanations, Graying the Black Box, Perturbation Saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from temporal_explanations_4_rl.agent_networks import load_dopamine_dqn_flax_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from temporal_explanations_4_rl.plan import Plan\n",
    "\n",
    "from temporal_explanations_4_rl.dataset import (\n",
    "    load_atari_obs,\n",
    "    load_state_values,\n",
    "    load_trajectories,\n",
    "    load_discrete_actions,\n",
    "    load_q_values,\n",
    ")\n",
    "from temporal_explanations_4_rl.explain import (\n",
    "    generate_dataset_explanation,\n",
    "    generate_skill_explanation,\n",
    ")\n",
    "from temporal_explanations_4_rl.graying_the_black_box import (\n",
    "    load_network_features,\n",
    "    pca_reduce_features,\n",
    "    run_tsne,\n",
    "    SpatioTemporalKMeans,\n",
    ")\n",
    "from temporal_explanations_4_rl.plot import animate_observations\n",
    "from temporal_explanations_4_rl.explain import (\n",
    "    generate_atari_perturbation_saliency_explanation,\n",
    "    generate_atari_grad_cam_explanation,\n",
    "    atari_greyscale_saliency_map,\n",
    ")\n",
    "from temporal_explanations_4_rl.skill import (\n",
    "    skill_labels_to_trajectory_skills,\n",
    ")\n",
    "from temporal_explanations_4_rl.utils import (\n",
    "    load_embedding,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent_name = \"dqn_adam_mse\"\n",
    "env_name = \"Breakout\"\n",
    "\n",
    "network_root_folder = \"../models/dopamine/jax\"\n",
    "dataset_folder = f\"../datasets/{agent_name}-{env_name}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent_model_def, agent_model_params = load_dopamine_dqn_flax_model(\n",
    "    env_name, network_root_folder\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_dataset_obs = load_atari_obs(f\"{dataset_folder}/trajectories\")\n",
    "training_dataset_state_values = load_state_values(f\"{dataset_folder}/trajectories\")\n",
    "training_dataset_trajectories = load_trajectories(f\"{dataset_folder}/trajectories\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate observation to explain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_dataset_folder = f\"../../datasets/explanation-testing/{agent_name}-{env_name}\"\n",
    "\n",
    "testing_obs_dataset = load_atari_obs(f\"{testing_dataset_folder}/trajectories\")\n",
    "testing_action_dataset = load_discrete_actions(f\"{testing_dataset_folder}/trajectories\")\n",
    "testing_q_values_dataset = load_q_values(f\"{testing_dataset_folder}/trajectories\")\n",
    "\n",
    "f\"{testing_obs_dataset.shape=}, {testing_action_dataset.shape=}, {testing_q_values_dataset.shape=}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if os.path.exists(f\"{testing_dataset_folder}/explanation-obs.npz\"):\n",
    "    with np.load(\n",
    "        f\"{testing_dataset_folder}/explanation-obs.npz\", allow_pickle=True\n",
    "    ) as file:\n",
    "        num_explanations = int(file[\"num_explanations\"])\n",
    "        obs_length = int(file[\"obs_length\"])\n",
    "        explain_time_steps = np.array(\n",
    "            [\n",
    "                file[f\"explain-{pos}\"].item()[\"time_step\"]\n",
    "                for pos in range(num_explanations)\n",
    "            ],\n",
    "            dtype=int,\n",
    "        )\n",
    "        explain_obs = np.array(\n",
    "            [file[f\"explain-{pos}\"].item()[\"obs\"] for pos in range(num_explanations)],\n",
    "            dtype=np.uint8,\n",
    "        )\n",
    "        explain_actions = np.array(\n",
    "            [\n",
    "                file[f\"explain-{pos}\"].item()[\"action\"]\n",
    "                for pos in range(num_explanations)\n",
    "            ],\n",
    "            dtype=int,\n",
    "        )\n",
    "else:\n",
    "    num_explanations = 5\n",
    "    padding = 20\n",
    "    obs_length = 20\n",
    "\n",
    "    explain_time_steps = np.zeros(num_explanations, dtype=int)\n",
    "    mask = np.ones_like(testing_action_dataset)\n",
    "    for pos in range(num_explanations):\n",
    "        time_step = np.argmax(\n",
    "            np.where(mask, np.std(testing_q_values_dataset, axis=1), mask)\n",
    "        )\n",
    "        explain_time_steps[pos] = time_step\n",
    "        mask[\n",
    "            np.arange(max(0, time_step - padding), min(time_step + padding, len(mask)))\n",
    "        ] = 0\n",
    "\n",
    "    explain_obs = testing_obs_dataset[explain_time_steps]\n",
    "    np.savez_compressed(\n",
    "        f\"{testing_dataset_folder}/explanation-obs.npz\",\n",
    "        num_explanations=num_explanations,\n",
    "        padding=padding,\n",
    "        obs_length=obs_length,\n",
    "        **{\n",
    "            f\"explain-{pos}\": {\n",
    "                \"time_step\": time_step,\n",
    "                \"obs\": testing_obs_dataset[time_step],\n",
    "                \"action\": testing_action_dataset[time_step],\n",
    "            }\n",
    "            for pos, time_step in enumerate(explain_time_steps)\n",
    "        },\n",
    "    )\n",
    "\n",
    "f\"{explain_obs.shape=}, {num_explanations=}, {obs_length=}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/explanations\"):\n",
    "    os.mkdir(f\"{testing_dataset_folder}/explanations\")\n",
    "\n",
    "for pos, time_step in enumerate(explain_time_steps):\n",
    "    if not os.path.exists(f\"{testing_dataset_folder}/explanations/explain-{pos}.mp4\"):\n",
    "        print(f\"Animating explanation {pos=} at {time_step=}\")\n",
    "        _, _, animation = animate_observations(\n",
    "            testing_obs_dataset[max(0, time_step - obs_length) : time_step],\n",
    "            return_html_animation=False,\n",
    "        )\n",
    "        animation.save(f\"{testing_dataset_folder}/explanations/explain-{pos}.mp4\")\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agents have a cunning plan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env_autoencoder = tf.keras.models.load_models(\n",
    "    f\"{dataset_folder}/models/autoencoder.params\"\n",
    ")\n",
    "policy_similarity_model = tf.keras.models.load_models(\n",
    "    f\"{dataset_folder}/models/policy-similarity.params\"\n",
    ")\n",
    "\n",
    "pse_embedding = load_embedding(f\"{dataset_folder}/embedding/pse-dense.npz\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset similarity explanation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/cunning-dataset-similarity\"):\n",
    "    os.mkdir(f\"{testing_dataset_folder}/cunning-dataset-similarity\")\n",
    "\n",
    "for pos, obs in enumerate(explain_obs):\n",
    "    print(f\"{pos=}\")\n",
    "    obs_embedding = env_autoencoder.encode(obs)\n",
    "    dataset_explanation_obs = generate_dataset_explanation(\n",
    "        obs_embedding, pse_embedding, training_dataset_obs[..., -1]\n",
    "    )\n",
    "\n",
    "    for num, explanation in enumerate(tqdm(dataset_explanation_obs)):\n",
    "        _, _, animation = animate_observations(explanation, return_html_animation=False)\n",
    "        animation.save(\n",
    "            f\"{testing_dataset_folder}/cunning-dataset-similarity/explain-{pos}-version-{num}.mp4\"\n",
    "        )\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Skill explanations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/cunning-skill-explain\"):\n",
    "    os.mkdir(f\"{testing_dataset_folder}/cunning-skill-explain\")\n",
    "\n",
    "pse_clustering = None\n",
    "pse_skill_transitions = None\n",
    "\n",
    "for pos, obs in enumerate(tqdm(explain_obs)):\n",
    "    obs_embedding = env_autoencoder.encode(obs)\n",
    "    obs_skill = pse_clustering.label(obs_embedding)\n",
    "    skill_explanation_obs = generate_skill_explanation(\n",
    "        obs_embedding,\n",
    "        obs_skill,\n",
    "        pse_embedding,\n",
    "        pse_skill_transitions,\n",
    "        training_dataset_obs[..., -1],\n",
    "    )\n",
    "\n",
    "    for num, explanation in enumerate(skill_explanation_obs):\n",
    "        _, _, animation = animate_observations(explanation, return_html_animation=False)\n",
    "        animation.save(\n",
    "            f\"{testing_dataset_folder}/cunning-skill-explain/explain-{pos}-version-{num}.mp4\"\n",
    "        )\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graying the black box explanation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrain graying the black box with explanation obs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/graying-embedding.npz\"):\n",
    "    print(f\"Generating graying the black box embedding\")\n",
    "    training_dataset_dense_features = load_network_features(\n",
    "        f\"{dataset_folder}/dense-features.npz\"\n",
    "    )\n",
    "    for time_step in explain_time_steps:\n",
    "        _, network_state = agent_model_def.apply(\n",
    "            agent_model_params, testing_obs_dataset[time_step], mutable=\"intermediates\"\n",
    "        )\n",
    "        np.append(\n",
    "            training_dataset_dense_features, network_state[\"intermediates\"][\"dense\"][0]\n",
    "        )\n",
    "\n",
    "    graying_reduced_features, _, _ = pca_reduce_features(\n",
    "        training_dataset_dense_features\n",
    "    )\n",
    "    print(f\"Graying reduced features: {graying_reduced_features.shape}\")\n",
    "    run_tsne(\n",
    "        graying_reduced_features,\n",
    "        f\"{testing_dataset_folder}/graying-embedding.npz\",\n",
    "        n_iter=1000,\n",
    "    )\n",
    "\n",
    "graying_embedding = load_embedding(f\"{testing_dataset_folder}/graying-embedding.npz\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_clusters, window_size = 15, 10\n",
    "graying_clustering_model = SpatioTemporalKMeans(\n",
    "    n_clusters=num_clusters, window_size=window_size\n",
    ")\n",
    "# We ignore the explanation obs as the trajectory information is unknown\n",
    "clustering_labels = graying_clustering_model.fit(\n",
    "    graying_embedding[:-num_explanations],\n",
    "    training_dataset_state_values,\n",
    "    training_dataset_trajectories,\n",
    ")\n",
    "\n",
    "skill_trajectories = skill_labels_to_trajectory_skills(\n",
    "    clustering_labels, num_clusters, training_dataset_trajectories\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/graying-skill-explain\"):\n",
    "    os.mkdir(f\"{testing_dataset_folder}/graying-skill-explain\")\n",
    "\n",
    "for pos in tqdm(range(num_explanations)):\n",
    "    explain_obs_embedding = graying_embedding[-num_explanations + pos]\n",
    "    explain_obs_skill = np.argmax(\n",
    "        np.linalg.norm(\n",
    "            graying_clustering_model.cluster_centers - explain_obs_embedding, axis=-1\n",
    "        )\n",
    "    )\n",
    "    plan = Plan(skill_trajectories)\n",
    "\n",
    "    skill_explanation_obs = generate_skill_explanation(\n",
    "        explain_obs_embedding,\n",
    "        explain_obs_skill,\n",
    "        graying_embedding[:-num_explanations],\n",
    "        plan,\n",
    "        training_dataset_obs[..., -1],\n",
    "    )\n",
    "\n",
    "    for num, explanation in enumerate(skill_explanation_obs):\n",
    "        _, _, animation = animate_observations(explanation, return_html_animation=False)\n",
    "        animation.save(\n",
    "            f\"{testing_dataset_folder}/cunning-skill-explain/explain-{pos}-version-{num}.mp4\"\n",
    "        )\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perturbation-based saliency map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/perturbation-saliency\"):\n",
    "    os.mkdir(f\"{testing_dataset_folder}/perturbation-saliency\")\n",
    "\n",
    "for pos, agent_obs in enumerate(tqdm(explain_obs)):\n",
    "    saliency_map, saliency_values = generate_atari_perturbation_saliency_explanation(\n",
    "        np.expand_dims(agent_obs, axis=0), agent_model_def, agent_model_params\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(\n",
    "        atari_greyscale_saliency_map(np.expand_dims(agent_obs, axis=0), saliency_map),\n",
    "        cmap=\"gray\",\n",
    "    )\n",
    "    plt.savefig(f\"{testing_dataset_folder}/perturbation-saliency/explain-{pos}.png\")\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grad-cam saliency maps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{testing_dataset_folder}/grad-cam-saliency\"):\n",
    "    os.mkdir(f\"{testing_dataset_folder}/grad-cam-saliency\")\n",
    "\n",
    "for pos, obs in enumerate(tqdm(explain_obs)):\n",
    "    saliency_map, _ = generate_atari_grad_cam_explanation(\n",
    "        agent_model_def, agent_model_params, obs, explain_actions[pos]\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(atari_greyscale_saliency_map(obs, saliency_map))\n",
    "    plt.savefig(f\"{testing_dataset_folder}/grad-cam-saliency/explain-{pos}.png\")\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
